---
title: "HW 6"
output: github_document
date: "2025-11-17"
author: "Julia Gray"
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(patchwork)
library(glmnet)
library(modelr)
library(mgcv)

knitr::opts_chunk$set(
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Get data:

```{r}
homicide_df = read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") |> 
  janitor::clean_names() |> 
  mutate(
    reported_date = as.Date(as.character(reported_date), format = "%y%m%d"),
    city_state = paste(city, state, sep=", "),
    solved = as.numeric(disposition %in% c("Closed by arrest")),
    victim_age = as.numeric(victim_age),
    victim_race = fct_relevel(victim_race, "White")
  ) |> 
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    !victim_age %in% c(NA),    #remove age is NA
    victim_race %in% c("White", "Black")
  )

baltimore_df = homicide_df |> 
  filter(
    city_state == "Baltimore, MD"
  ) |> 
  select(solved, victim_age, victim_race, victim_sex)
```

Fit model for Baltimore:

```{r}
or_balt = 
  baltimore_df |> 
  glm(solved ~ victim_age + victim_race + victim_sex, data = _, family = binomial()) 

or_balt |> 
  broom::tidy(conf.int = TRUE, exponentiate = TRUE) |> 
  select(term, estimate, conf.low, conf.high, p.value) |> 
  knitr::kable(digits = 3)
```

Fit model for all cities:

```{r}
fit_or = function(input_city){
  
  fit = 
    homicide_df |>
    filter(city_state == input_city) |>
    glm(formula = solved ~ victim_age + victim_race + victim_sex, data = _, family = binomial()) |>
    broom::tidy(conf.int = TRUE, exponentiate = TRUE) |>
    filter(term == "victim_sexMale") |>
    select(estimate, conf.low, conf.high, p.value)

  fit
}

ny_test = fit_or('New York, NY')

or_all_cities = 
  tibble(
    city_s = unique(pull(homicide_df, city_state))
    ) |> 
  mutate(fit_estimates = map(city_s, fit_or)) |> 
  unnest(fit_estimates)
```

Plot the results

```{r}
or_all_cities |> 
  mutate(city_s = fct_reorder(city_s, estimate)) |> 
  ggplot(aes(x = estimate, y = city_s)) + 
  geom_point() + 
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) +
  geom_vline(xintercept = 1, color = "red") +
  xlim(0, 4) +
  ylab("City, State") +
  xlab("OR of homicide being solved (male vs. female)")
```

An odds ratio of 1 (shown on the plot as a red line), means there is no difference in the odss of the homicide being solved between males and females. An odds ratio greater than 1 means that homicides where the victim is male have higher odds of being solved and vice versa. The confidence interval is shown by the error bars and where it crosses 1 the results are not significant. 

## Problem 2

Get the data:

```{r}
data("weather_df")
```

Write the bootstrap function, run 5000 times and get $\widehat{r}^2, $\hat{\beta}_1$ and $\hat{\beta}_2$ :

```{r}
get_bootstrap = function(df) {
  slice_sample(df, prop = 1, replace = TRUE)
}

#set this to 100 for now to make knitting faster - remember to change back to 5000
weather_sample_df = tibble(iter = 1:100) |> 
  mutate(
    bs_sample = map(iter, \(i) get_bootstrap(df = weather_df)),
    sample_lm = map(bs_sample, \(df) lm(tmax~tmin + prcp, data = df)),
    r_sq_hat = map(sample_lm, \(model) model |> 
                     broom::glance() |> pull(r.squared)),
    beta_1_hat = map_dbl(sample_lm, \(model) model |> 
                           broom::tidy() |> filter(term == "tmin") |> pull(estimate)),
    beta_2_hat = map_dbl(sample_lm, \(model) model |> 
                           broom::tidy() |> filter(term == "prcp") |> pull(estimate)),
    beta_ratio = beta_1_hat / beta_2_hat
  )
```

Plot the distribution of estimates:

```{r}
b1_plot = weather_sample_df |> 
  ggplot(aes(x = beta_1_hat)) + geom_density()

b2_plot = weather_sample_df |> 
  ggplot(aes(x = beta_2_hat)) + geom_density()

b1_plot + b2_plot
```

$\hat{\beta}_1$ and $\hat{\beta}_2$ are both approximately normally distributed with means `r round(mean(pull(weather_sample_df, beta_1_hat)), digits = 3)` and `r round(mean(pull(weather_sample_df, beta_2_hat)), digits = 3)`.

Provide 95% confidence interval for $\widehat{r}^2 and $\hat{\beta}_1$ / $\hat{\beta}_2$ :

```{r}
weather_sample_df |> 
  select(beta_1_hat, beta_2_hat, beta_ratio, r_sq_hat) |> 
  mutate(r_sq_hat = as.numeric(r_sq_hat)) |> 
  pivot_longer(
    cols = c(beta_1_hat, beta_2_hat, beta_ratio, r_sq_hat),
    names_to = "estimate",
    values_to = "value"
  ) |> 
  group_by(estimate) |> 
  reframe(
    ci.lower = quantile(value, probs = 0.025),
    ci.upper = quantile(value, probs = 0.975)
  ) |> 
  knitr::kable()
```

## Problem 3

Load and clean the data:

```{r}
birth_df = read_csv('./data/birthweight.csv') |> 
  mutate(
    #convert categories to factors
    sex = as.factor(case_match(
      babysex,
      1 ~ "male", 
      2 ~ "female"
    )),
    father_race = as.factor(case_match(
      frace,
      1 ~ "White",
      2 ~ "Black",
      3 ~ "Asian",
      4 ~ "Puerto Rican",
      8 ~ "Other",
      9 ~ "Unknown",
    )),
    mother_race = as.factor(case_match(
      mrace,
      1 ~ "White",
      2 ~ "Black",
      3 ~ "Asian",
      4 ~ "Puerto Rican",
      8 ~ "Other",
      9 ~ "Unknown",
    )),
    malform = as.factor(case_match(
      malform,
      0 ~ "absent",
      1 ~ "present"
    )),
    #convert all units to lbs and inches:
    blength_in = blength / 2.54,
    bhead_in = bhead / 2.54,
    bwt_lb = bwt / 453.6, # converting from grams to lbs
  ) |> 
  rename(
      avg_cig_per_day = smoken,
      m_wt_lb = delwt,
      m_ppwt_lb = ppwt,
      m_ppbmi = ppbmi,
      m_age_delivery = momage,
      m_age_menarche = menarche,
      m_wtgain_lb = wtgain,
      m_height = mheight
    ) |> 
  select(sex, father_race, mother_race, blength_in, bhead_in, bwt_lb, fincome,
         gaweeks, malform, m_height, m_wt_lb, m_ppwt_lb, m_wtgain_lb,
         m_age_delivery, m_age_menarche, avg_cig_per_day, parity, pnumlbw, pnumsga)
```

First let's look at the data by the most obvious predictor which is mother's weight gain:

```{r}
birth_df |> 
  ggplot(aes(x = bwt_lb, y = m_wtgain_lb)) + 
  geom_point(alpha = .5)
```

Use LASSO to build model:

```{r}
x = model.matrix(bwt_lb ~ ., birth_df)[,-1]
y = birth_df |> pull(bwt_lb)

lambda = 10^(seq(-2, 2.75, 0.1))

lasso_fit =
  glmnet(x, y, lambda = lambda)

lasso_cv =
  cv.glmnet(x, y, lambda = lambda)

lambda_opt = lasso_cv[["lambda.min"]]
lambda_1se = lasso_cv[["lambda.1se"]] 

cv_min = lasso_cv |> broom::tidy() |> filter(lambda == lambda_opt) |> pull(estimate)
cv_1se = lasso_cv |> broom::tidy() |> filter(lambda == lambda_1se) |> pull(estimate)
```

Plot models:

```{r}
lasso_fit |> 
  broom::tidy() |> 
  select(term, lambda, estimate) |> 
  complete(term, lambda, fill = list(estimate = 0) ) |> 
  filter(term != "(Intercept)") |> 
  ggplot(aes(x = log(lambda, 10), y = estimate, group = term, color = term)) + 
  geom_path() + 
  geom_vline(xintercept = log(lambda_opt, 10), color = "blue", size = 1.2) +
  geom_vline(xintercept = log(lambda_1se, 10), color = "lightblue", size = 1.2) +
  theme(legend.position = "none")

lasso_cv |> 
	broom::tidy() |> 
  mutate(
    m_cv_error = estimate # mean cross-validated error
  ) |> 
	ggplot(aes(x = log(lambda, 10), y = m_cv_error)) +
	geom_point() + 
  geom_vline(xintercept = log(lambda_opt, 10), color = "blue") + 
  geom_vline(xintercept = log(lambda_1se, 10), color = "lightblue") + 
  geom_hline(yintercept = cv_min, color = "green") + 
  geom_hline(yintercept = cv_1se, color = "lightgreen") 
```

We can see the cross validated error is basically the same for optimal lambda (all predictors) and lambda within 1 standard deviation.

`r cv_1se` - `r cv_min` = `r cv_1se - cv_min`

Use lambda within 1 se:

```{r}
lasso_fit_1se = glmnet(x, y, lambda = lambda_1se)
```

Get predictions
```{r}
bwt_predictions = 
  birth_df |> 
  select(bwt_lb) |> 
  mutate(
    bwt_lb_pred = predict(lasso_fit_1se, newx = x)[,1],
    residuals = bwt_lb - bwt_lb_pred
  )
```

Plot residuals:

```{r}
bwt_predictions |>
  ggplot(aes(x = bwt_lb_pred, y = residuals)) +
  geom_point(alpha = 0.5)
```

Looks good let's compare to the other models

```{r}
lm_main_effects = function(df) {
  lm(bwt_lb ~ blength_in + gaweeks, data = df)
}

lm_3_way_interaction = function(df) {
  lm(bwt_lb ~ bhead_in + blength_in + sex + 
       bhead_in*blength_in + bhead_in*sex + 
       blength_in*sex + bhead_in*blength_in*sex, 
     data = birth_df)
}

glm_lambda_1se = function(df) {
  y = df |> pull(bwt_lb) 
  x = model.matrix(bwt_lb ~., df)[,-1]
  glmnet(x, y, lambda = lambda_1se)
}

get_rmse = function(model, df) {
  
  x = model.matrix(bwt_lb ~., df)[,-1]
  
  df = df |> 
    mutate(bwt_lb_pred = predict(model, newx = x)[,1]) 
  
  actual = df |> pull(bwt_lb)
  predicted =  df |> pull(bwt_lb_pred)
  rmse = sqrt(mean((actual - predicted)^2))
  rmse
}
```

Perform cross-validation:

```{r}
cv_df = 
  crossv_mc(birth_df, n = 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  ) |> 
  #fit models => use training data
  mutate(
    glm = map(train, glm_lambda_1se),
    lm_me = map(train, lm_main_effects),
    lm_3wi = map(train, lm_3_way_interaction)
  ) |> 
  #get rmse => use testing data
  mutate(
    rmse_glm = map2_dbl(glm, test, get_rmse),
    rmse_linear_simple = map2_dbl(lm_me, test, rmse),
    rmse_linear_complex = map2_dbl(lm_3wi, test, rmse)
  )
```

Look at the RMSE for each model:

```{r}
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin()
```

RMSE is lowest in glm model

```{r echo=FALSE}
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  group_by(model) |> 
  summarize(
    mean_RMSE = mean(rmse)
  ) |> 
  knitr::kable(digits = 3)
```





